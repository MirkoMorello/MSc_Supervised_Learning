{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L13 09/05/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification and localization\n",
    "\n",
    "Usually, we have the same backbone, then we have two branches that fulfill two different tasks, one is a classification head, the other is a regression head.ype of \n",
    "Two type to do this, the regression can be classs agnostic or class specific, getting information about the class or not from the classification head, class specifics returns 4 numbers for every box, bounding every type of class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Object detection\n",
    "It's detection as classification, we have a sliding windows trough the image, changing location of this sliding bounding box, we classify that position and ask if it contains our object of interest or not, this is a brute force solution, not really feasible.  \n",
    "More likely, we have to use a computationally demanding classifier so this his not feasible, the solution is to look at tiny subset of possible positions. \n",
    "We have a region proposal model, it finds possible regions and propose them as being the object of interest, we then have to classify them.  \n",
    "\n",
    "\n",
    "### Selective search:\n",
    "Hand-crafted methods for segmentation, it exploits the concept of superpixels, we look for similarity in:\n",
    "- Color\n",
    "- Texture\n",
    "- Size\n",
    "- Fill\n",
    "\n",
    "The Objective is to produce multiple overlapping proposals, for example a wheel is an object, but is also part of a bigger object, a car."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "So I have a initial segmentation ML algorithm, then I give it to a CNN model, trim the last layer and give the results of the previous layer to an SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There are three extra steps to make our work better:\n",
    "- Bounding box regression (4/5 % better performances)\n",
    "- Non maximum suppression\n",
    "  - Sort all the bounding bozes by confidence score\n",
    "  - discard the boxes with low confidenxce scores\n",
    "  - greedily select the one wit the highest score\n",
    "  - Discar boxes with high overlap with the previously selected one, and go back to previous step\n",
    "- Hard nefarive mining, automatically select useful negative samples, like in Viola Jones, for example, if i want to find a face, a plain region in the sky is an easy negative, face looking pattern in foliage is hard nefative\n",
    "  - Train the model with random negatives\n",
    "  - run the model on an annotated validation set\n",
    "  - select all false positives as (hard) negative examples\n",
    "  - We have to be careful! the validation set must be exhaustively annotated, otherwise we could classify as false positive true positive"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### RCNN bottlenecks:\n",
    "1. Selective search is slow\n",
    "2. Feature extraction is inefficient\n",
    "   - 2000 candidate windows per image\n",
    "   - extracting neural fearures for each dandidate\n",
    "   - mostly overlapped ...\n",
    "\n",
    "### RCNN problems\n",
    "1. SVMSA and regressor are post-hoc: CNN features are not updated in response to SVMs and regressors (they can't influence what's before them)\n",
    "2. Complex multistage teraining pipeline\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Fast R-CNN Classification\n",
    "- Replace SVM with softmax (neural) classification\n",
    "- optimize the sum of two losses:\n",
    "  - Classification\n",
    "  - BBox correction\n",
    "\n",
    "This solves the bottleneck number 2, but not the problem number 2.  \n",
    "For solving the problem number 1, we share ...  \n",
    "For solving problem number 1 and 2, we just train the whole system ent-to-end all at once"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Faster R-CNN\n",
    "fast rcnn is fast asf, but faster is faster.  \n",
    "The idea is that now we insert a region proposal network after the last convolutional layer, RPN trained to produce region proposals directly, no need for external region proposals.  \n",
    "After RPN, use RoI Poooling and upstream classifier and bbos regressor just lie fast rcnn.  \n",
    "\n",
    "### RPN\n",
    "We use N anchor boxes at each location, anchors are translation invariant, use the same ones at every location, regression gives the offsets from anchor boxes, classification fives the probability that each regressed anchor shows an object  \n",
    "\n",
    "Main ideas are:\n",
    "- Replace selective search with region proposal network (RPN)\n",
    "- Can be trained in two iterating phases, or end to end"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![alt text](image.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
