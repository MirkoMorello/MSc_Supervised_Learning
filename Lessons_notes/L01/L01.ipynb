{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# L01 07/03/24"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Basic Concepts"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of generating models from data is called learning or training, which is accomplished by a learning algorithm  \n",
    "THe learned Model can be called a hypothesis, o learner  \n",
    "There are different learning settings, among which the most common ones are supervised learning and unsupervised learning  \n",
    "In supervised learning the goal is to predisct the value of a target feeature on unseen instances and the learned model is also called a predictor\n",
    "- for example, if we want to predict the shape of three gaussian data points, we call \"cross\" and \"circle\" labels\n",
    "- the predictor should be able to predict the label of an instance for which the label infoermation is unknown, e.g. (.2, .3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Unsupervised learning instead **does not rely on label information**, its goal is to discover some inherent distribution information in the data (for example clustering)\n",
    "Since the fundamental goal of learning is **generalization**, a good learner should generalize well, so having a small generalization error, also called the **prediction error**.\n",
    "it is infeasible to estimate the generalization error directly, since that requires knowing the ground truth label information which is unknopwn for unseen instances."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The process of applying a learned model to unseen data is called **testing**  \n",
    "before testing, a learned model often needs to be configured, e.g. tuning the paramenters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Formal formulation of the learning process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "let X be the instance space, $\\mathcal D$ a distribution over $X$ and $f(*)$ the ground truth target function.  \n",
    "Given a training data set $d = {(x1, y1), (x2, y2), ... (xn, yn)}$ where the instances $x_i$ are drawn i.i.d. from $\\mathcal D$ and $y_i = f(x_i)$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking classification as an example, the goal is to construct a learner $h(*)$ which **minimizes** the generalization error:  \n",
    "$ err(h) = \\mathbb{E}_{x\\sim \\mathcal D} [\\mathbb I (h(x) \\ne f(x))] $ \n",
    "where $\\mathbb I(*)$ is the indicator function which takes $1$ if its argukment is true, and $0$ otherwise."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Popular learning algorithms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### LDA (Linear discriminant analysis)\n",
    "\n",
    "A linear classifier consists of weigth vector w and a bias b.\n",
    "given an instance x, the predicted class label y is obtained according to y = sign(w**t x + b)  \n",
    "A classical linear algorithm is FIscher linear discriminant Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Decision trees"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Decision trees that have perfect score on the training set usually are not so good on the generalization aspect due to overfitting, to avoid this, we employ the technique of pruning, divided in:\n",
    "- pre-pruning, which tries to prune branches when the tree is being grown\n",
    "- post-pruning, re-examines fully grown trees to decide which branches should be removed."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Neural networks\n",
    "\n",
    "also called artificial neural networks, simulating biolopgical neural networks.  \n",
    "Neuron is also called **unit**, which is the basic computational component in neural networks.\n",
    "input signals are multiplied wit  corresponding weigths, and then compared to a threshold (**bias**). if the result is higher than the bias, the neuson is activated and the output signal is generated by an activation function.\n",
    "the goal is to determine the values of the connection weights and the biases of the neurons.  \n",
    "the whole neural network can be regarded as a differentiable function which can be optimized by gradient descent method.\n",
    "the most NN training algorithm is **Back-Propagation (BP)**. \n",
    "\n",
    "# Learning algorithms:\n",
    "\n",
    "## Backpropagation\n",
    "\n",
    "## k-Nearest Neighbor\n",
    "it's a lazy kind of learninig algorithm since it doesn't really learn but it stores the training set.\n",
    "- 1-NN is also called nearest neighbor classifier.\n",
    "\n",
    "## Support vector machines and kernel methods\n",
    "SVMa, originally designed for binary classification, are large margin classifiers that try to se√®arate instances of different classes with the maximum margin **hyperplane**.\n",
    "It's better than the knn because it's safer to put the line in-between the classes instead of exactly at the boundary of one.  \n",
    "The is a kernel trick to avoid going to a higher dimensional plane to accomplish the learning task in an easier way. WE avoid to compute the inner product in the higher dimensional plane, but we take it from the kernel, avoiding many calculations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Evaluation and comparison\n",
    "\n",
    "We have to evaluate our data on the validation set, it's foolish to do it on the training set since we train exactly on it.\n",
    "- **stratification**, stratifyng the sampling, splitting in a balanced way the trainig and validating set.\n",
    "- **cross-validation**, the validation set is splitted into k equal-size disjoint subsets, and then k runs of training-tests are performed.\n",
    "- **t-times k-fold cross-validation**, to reduce the influence of randomness introduced by data split, the k fold cross validation can be repeated t times\n",
    "- After obtaining the estimated errors, we can compare different learning algorithms. a simple comparison on average errors, however, it's not completely winning because it can be dependent on the training set etc.\n",
    "- we cross-validate stuff\n",
    "- To compare learning algorithms that can br run only once, the **McNemar's test** can be used instead.\n",
    "- If we have to evaluate multiple learning algorithms on multiple data sets, we can conduct the **Friedman test**. It can be visualized by plotting the critical difference diagram, where each algorithm corresponds to a bar centered at the average rank with the width of critical difference value, the more the algorithm lie away from the mean, the better they are."
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
